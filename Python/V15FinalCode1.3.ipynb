{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from openpyxl import load_workbook\n",
    "import gc\n",
    "import glob\n",
    "import warnings\n",
    "from pandas import ExcelWriter\n",
    "warnings.simplefilter('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOMfield_mapping = pd.read_excel('./V15 BOM-RuleTable Mapping 18th Aug 2020.xlsx', \\\n",
    "                                 usecols=['Worksheet Key', 'Condition', 'BOM Fields', 'Rule Table Field'])\n",
    "BOMfield_mapping.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinkedQuestionnaireField_mapping = pd.read_excel('./Linked Questionnaire Field Mapping.xlsx')\n",
    "LinkedQuestionnaireField_mapping['Linked worksheet'] = LinkedQuestionnaireField_mapping['Linked worksheet'].str.strip()\n",
    "LinkedQuestionnaireField_mapping['Controller'] = LinkedQuestionnaireField_mapping['Controller'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_mapping = pd.read_excel('./Entity Mapping.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "entityName = 'SG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22561"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wholeFile = pd.read_excel(glob.glob('./Data/{}/InterviewWithQuestionnaires_*.xls*'.format(entityName))[0], \\\n",
    "                          sheet_name=None, header=None)\n",
    "\n",
    "\n",
    "parsedResultData = {}\n",
    "for key in wholeFile.keys():\n",
    "    if key not in ['Interview', 'Table of Contents', 'Available Reference Values', 'Overrides']:\n",
    "        parsedResultData[wholeFile[key].iloc[0,0].split(':')[1].replace(', Class', '').strip()] = wholeFile[key]\n",
    "    else:\n",
    "        parsedResultData[key] = wholeFile[key]\n",
    "\n",
    "worksheetMapping = {}\n",
    "for key in wholeFile.keys():\n",
    "    if key not in ['Interview', 'Table of Contents', 'Available Reference Values', 'Overrides']:\n",
    "        worksheetMapping[wholeFile[key].iloc[0,0].split(':')[1].replace(', Class', '').strip()] = key\n",
    "    else:\n",
    "        worksheetMapping[key] = key\n",
    "        \n",
    "del wholeFile\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_table_beginnings(df):\n",
    "    '''\n",
    "    Function to identify from which row each of the 3 main tables start\n",
    "    '''\n",
    "    table_beginning_rows_dict = {}\n",
    "    row = 0\n",
    "    QnA_table_beginning_Found = False\n",
    "    while (QnA_table_beginning_Found == False) & (row < df.shape[0]):\n",
    "        if str(df.iloc[row, 0]).find('Underwriter Comments') != -1:\n",
    "            QnA_table_beginning_Found = True\n",
    "        else:\n",
    "            row += 1\n",
    "    table_beginning_rows_dict['QnA_table_beginning_row'] = np.where(row == df.shape[0], 'None', row).flat[0]\n",
    "    \n",
    "    table_beginning_rows_dict['Controller_table_beginning_rows'] = []\n",
    "    for i in range(df.shape[0]):\n",
    "        if  str(df.iloc[i, 0]).find('Controller') != -1:\n",
    "            table_beginning_rows_dict['Controller_table_beginning_rows'].append(i)\n",
    "            \n",
    "    table_beginning_rows_dict['Rules_table_beginning_rows'] = []\n",
    "    for i in range(df.shape[0]):\n",
    "        if  (str(df.iloc[i, 0]).find('Rules') != -1) & (str(df.iloc[i, 0]).find('Controller') == -1):\n",
    "            table_beginning_rows_dict['Rules_table_beginning_rows'].append(i)\n",
    "        \n",
    "    return table_beginning_rows_dict\n",
    "\n",
    "\n",
    "def create_QuestionType_FilterType(inputString):\n",
    "    '''\n",
    "    Helper function to separate Question type and Filter type values into two separate columns\n",
    "    '''\n",
    "    value = inputString.values[0].split(',', maxsplit=1)\n",
    "    QuestionType = value[0].replace('Question Type = ', '')\n",
    "    if len(value) > 1:\n",
    "        FilterType = value[1].replace('Filter Type = ', '')\n",
    "    else:\n",
    "        FilterType = None\n",
    "    return QuestionType, FilterType\n",
    "\n",
    "\n",
    "def ranking(x):\n",
    "    '''\n",
    "    Helper function to initiate ranks based on 1st level of Question\n",
    "    '''\n",
    "    d = {}\n",
    "    for i in x.columns[1:]:\n",
    "        d[i + 100] = pd.factorize(x[i])[0]\n",
    "        d.update()\n",
    "    return pd.Series(d, index=[j + 100 for j in x.columns[1:]])\n",
    "\n",
    "\n",
    "def transform(x, rcol, col):\n",
    "    '''\n",
    "    Helper function to generate question-answers, question types, numbers and parents, assumes for now max 6 levels of questions\n",
    "    '''\n",
    "    i = 103\n",
    "    if len(rcol) == 1:\n",
    "        x['Question'] = x[0]\n",
    "        x['Question Type'] = x[1]\n",
    "        x['Answer'] = x[2]\n",
    "    elif len(rcol) == 2:\n",
    "        x['Question'] = x.apply(lambda y: y[0] if y[i] == 0 else y[i - 100], axis=1)\n",
    "        x['Question Type'] = x.apply(lambda y: y[1] if y[i] == 0 else y[i - 100 + 1], axis=1)\n",
    "        x['Answer'] = x.apply(lambda y: y[2] if y[i] == 0 else y[i - 100 + 2], axis=1)\n",
    "    elif len(rcol) == 3:\n",
    "        x['Question'] = x.apply(lambda y: y[0] if y[i] == 0 else (y[i - 100] if y[i + 3] == 0 else y[i - 100 + 3]),\n",
    "                                axis=1)\n",
    "        x['Question Type'] = x.apply(\n",
    "            lambda y: y[1] if y[i] == 0 else (y[i - 100 + 1] if y[i + 3] == 0 else y[i - 100 + 3 + 1]), axis=1)\n",
    "        x['Answer'] = x.apply(\n",
    "            lambda y: y[2] if y[i] == 0 else (y[i - 100 + 2] if y[i + 3] == 0 else y[i - 100 + 3 + 2]), axis=1)\n",
    "    elif len(rcol) == 4:\n",
    "        x['Question'] = x.apply(lambda y: y[0] if y[i] == 0 else (\n",
    "            y[i - 100] if y[i + 3] == 0 else (y[i - 100 + 3] if y[i + 6] == 0 else y[i - 100 + 6])), axis=1)\n",
    "        x['Question Type'] = x.apply(lambda y: y[1] if y[i] == 0 else (\n",
    "            y[i - 100 + 1] if y[i + 3] == 0 else (y[i - 100 + 3 + 1] if y[i + 6] == 0 else y[i - 100 + 6 + 1])), axis=1)\n",
    "        x['Answer'] = x.apply(lambda y: y[2] if y[i] == 0 else (\n",
    "            y[i - 100 + 2] if y[i + 3] == 0 else (y[i - 100 + 3 + 2] if y[i + 6] == 0 else y[i - 100 + 6 + 2])), axis=1)\n",
    "    elif len(rcol) == 5:\n",
    "        x['Question'] = x.apply(lambda y: y[0] if y[i] == 0 else (\n",
    "            y[i - 100] if y[i + 3] == 0 else (y[i - 100 + 3] if y[i + 6] == 0 else (y[i - 100 + 6] if y[i + 9] == 0 else y[i - 100 + 9]))), axis=1)\n",
    "        x['Question Type'] = x.apply(lambda y: y[1] if y[i] == 0 else (\n",
    "            y[i - 100 + 1] if y[i + 3] == 0 else (y[i - 100 + 3 + 1] if y[i + 6] == 0 else (y[i - 100 + 6 + 1] if y[i + 9] == 0 else y[i - 100 + 9 + 1]))), axis=1)\n",
    "        x['Answer'] = x.apply(lambda y: y[2] if y[i] == 0 else (\n",
    "            y[i - 100 + 2] if y[i + 3] == 0 else (y[i - 100 + 3 + 2] if y[i + 6] == 0 else (y[i - 100 + 6 + 2] if y[i + 9] == 0 else y[i - 100 + 9 + 2]))), axis=1)\n",
    "\n",
    "    x['Question'] = x['Question'].str.replace('<<<[0-9]*>>>', '')\n",
    "    x['Question Number'] = x[rcol].apply(lambda x: '.'.join(x.values.astype(str)), axis=1).str.replace('.0', '', regex=False)\n",
    "    x['Parent'] = x['Question Number'].apply(lambda x: x.rsplit('.', 1)[0])\n",
    "    final_tdf = x.drop(rcol, axis=1).drop(col, axis=1)\n",
    "    return final_tdf\n",
    "\n",
    "\n",
    "def rankDF(source):\n",
    "    '''\n",
    "    Helper function to split question-answers and rank hierarchies\n",
    "    '''\n",
    "    # Selecting and splitting 'Question and Answers' from source\n",
    "    splitSource = pd.DataFrame(source['Questions and Answers'].str.split('    ', expand=True))\n",
    "    obj_columns = list(splitSource.select_dtypes(include=['object']).columns.values)\n",
    "    splitSource[1000] = '<<<' + splitSource.index.astype(str) + '>>>'\n",
    "    qColList = [y for y in splitSource.columns if y % 3 == 0]\n",
    "    for i in qColList:\n",
    "        splitSource[i] = splitSource[i].combine(splitSource[1000], lambda a, b: b + a if a != '' and a is not None else a)\n",
    "    splitSource = splitSource.drop(1000, axis=1)\n",
    "    splitSource[obj_columns] = splitSource[obj_columns].replace([None], '0').replace(\"\", np.NaN).fillna(method='ffill')\n",
    "    splitSource['row'] = splitSource.index\n",
    "\n",
    "    # Generating Rank for Question Hierarchy\n",
    "    rankColList = [j + 100 for j in qColList]\n",
    "    colList = [x for x in range(len(qColList) * 3)]\n",
    "    qDF = splitSource[qColList].drop_duplicates()\n",
    "    qDF.reset_index(drop=True, inplace=True)\n",
    "    qRankDF = pd.DataFrame()\n",
    "    if len(qColList) > 1:\n",
    "        for i in qColList:\n",
    "            if i == 0:\n",
    "                qRankDF[100] = qDF[0].factorize()[0] + 1\n",
    "            else:\n",
    "                groupList = qColList[:i // 3]\n",
    "                qRankDF[i + 100] = qDF.groupby(groupList, sort=False).apply(ranking)[i + 100].explode().reset_index(\n",
    "                    drop=True)\n",
    "        rankedDf = pd.concat([qDF, qRankDF], axis=1)\n",
    "    else:\n",
    "        qDF[100] = qDF.index + 1\n",
    "        rankedDf = qDF\n",
    "\n",
    "    # merging Question Ranks with data\n",
    "    mid_df = pd.merge(splitSource, rankedDf, on=qColList)\n",
    "\n",
    "    # Adding columns to make Dataframe consistent.\n",
    "    for z in colList:\n",
    "        if z not in mid_df.columns:\n",
    "            mid_df[z] = 0\n",
    "    mid_df = mid_df.astype(object)\n",
    "    return mid_df, rankColList, colList\n",
    "\n",
    "\n",
    "def create_QnA_table(key, data, table_beginning_rows_dict):\n",
    "    '''\n",
    "    Function to create a dataframe for the QnA part, assumes for now that there are always 6 columns\n",
    "    '''\n",
    "    if len(table_beginning_rows_dict['Controller_table_beginning_rows']) > 0:\n",
    "        table_end_row = np.int8(table_beginning_rows_dict['Controller_table_beginning_rows'][0]) - 1\n",
    "    elif len(table_beginning_rows_dict['Rules_table_beginning_rows']) > 0:\n",
    "        table_end_row = np.int8(table_beginning_rows_dict['Rules_table_beginning_rows'][0]) - 1\n",
    "    else:\n",
    "        table_end_row = data.shape[0] + 1\n",
    "\n",
    "    if key == 'Interview':\n",
    "        source = data.iloc[np.int8(table_beginning_rows_dict['QnA_table_beginning_row']) + 1: table_end_row, 0:7]\n",
    "        source.columns = ['Underwriter Comments', 'Section Name', 'Key Name', 'BOM Fields', 'Questions and Answers',\n",
    "                          'DisclosureType and Questionnaire', 'Help Text']\n",
    "        source.drop(['Section Name'], axis=1, inplace=True)\n",
    "    else:\n",
    "        source = data.iloc[np.int8(table_beginning_rows_dict['QnA_table_beginning_row']) + 1: table_end_row, 0:6]\n",
    "        source.columns = ['Underwriter Comments', 'Key Name', 'BOM Fields', 'Questions and Answers',\n",
    "                          'DisclosureType and Questionnaire', 'Help Text']\n",
    "\n",
    "    source.dropna(inplace=True, how='all')\n",
    "    source = source.astype(object)\n",
    "    #     df.fillna('', inplace=True)\n",
    "    source.reset_index(drop=True, inplace=True)\n",
    "    disclosureCond = source['DisclosureType and Questionnaire'].str.contains('Disclosure Type = ') & source[\n",
    "        'DisclosureType and Questionnaire'].str.contains('Questionnaire = ')\n",
    "    if source[(disclosureCond)].empty:\n",
    "        source['Disclosure Type'] = source['DisclosureType and Questionnaire']\n",
    "        source['Questionnaire'] = np.NaN\n",
    "    else:\n",
    "        source[['Disclosure Type', 'Questionnaire']] = source['DisclosureType and Questionnaire'].str.split(',',\n",
    "                                                                                                            expand=True)\n",
    "\n",
    "    fsource = source.drop('DisclosureType and Questionnaire', axis=1)\n",
    "\n",
    "    # finding MIN and MAX for Numeric Question\n",
    "    minMaxCond = fsource['Questions and Answers'].str.contains('Minimum = ') & fsource[\n",
    "        'Questions and Answers'].str.contains('Maximum = ')\n",
    "    if fsource[minMaxCond].empty:\n",
    "        fsource['Min'] = np.NaN\n",
    "        fsource['Max'] = np.NaN\n",
    "    else:\n",
    "        fsource[['Min', 'Max']] = fsource[minMaxCond]['Questions and Answers'].str.replace('\\s{1,}=\\s{1,}',\n",
    "                                                                                           '=').str.strip().str.split(\n",
    "            ' ', 1, expand=True)\n",
    "    fsource['Classes'] = fsource[(fsource['Questions and Answers'].str.contains('Classes = '))]['Questions and Answers']\n",
    "    fsource['Available Units'] = fsource[(fsource['Questions and Answers'].str.contains('Available Units = '))][\n",
    "        'Questions and Answers']\n",
    "\n",
    "    clist = fsource.index[\n",
    "        fsource['Min'].notnull() | fsource['Classes'].notnull() | fsource['Available Units'].notnull()].tolist()\n",
    "    for i in clist:\n",
    "        fsource.at[i - 2, ['Min', 'Max', 'Classes', 'Available Units']] = fsource.loc[\n",
    "            i, ['Min', 'Max', 'Classes', 'Available Units']]\n",
    "\n",
    "    rdf, rcol, col = rankDF(fsource)\n",
    "    tdf = transform(rdf, rcol, col)\n",
    "    filteredDf = tdf[(tdf['Question Type'].str.contains(\"Question Type\"))].copy()\n",
    "    filtered0Df = pd.concat(\n",
    "        [filteredDf.groupby('Question Number').filter(lambda x: len(x) == 1),\n",
    "         filteredDf.groupby('Question Number').filter(lambda x: len(x) > 1)[\n",
    "             filteredDf.groupby('Question Number').filter(lambda x: len(x) > 1).Answer != '0']]\n",
    "    ).sort_values('Question Number')\n",
    "\n",
    "    jrdf = pd.merge(tdf, fsource, left_on=tdf.row, right_on=fsource.index)\n",
    "    jrdf = jrdf.drop(['key_0', 'row'], axis=1)\n",
    "\n",
    "    col = ['Question', 'Questions and Answers', 'Underwriter Comments', 'Key Name', 'BOM Fields', 'Help Text',\n",
    "           'Disclosure Type', 'Questionnaire', 'Min', 'Max', 'Classes', 'Available Units']\n",
    "    pdf = jrdf[col[2:]].dropna(axis=0, how='all')\n",
    "    BOM_df = pdf.merge(jrdf[col[:2]], left_index=True, right_index=True, how='left')\n",
    "    BOM_df['Questions and Answers'] = BOM_df['Questions and Answers'].str.strip()\n",
    "    qdf = BOM_df[(BOM_df['Question'].str.strip() == BOM_df['Questions and Answers'])].drop('Questions and Answers',\n",
    "                                                                                           axis=1).merge(filtered0Df,\n",
    "                                                                                                         on='Question').rename(\n",
    "        columns={\"Key Name\": \"Question Key Name\", \"BOM Fields\": \"Question BOM Fields\"})\n",
    "    adf = BOM_df[(BOM_df['Question'].str.strip() != BOM_df['Questions and Answers'])].merge(filtered0Df,\n",
    "                                                                                            right_on=['Question',\n",
    "                                                                                                      'Answer'],\n",
    "                                                                                            left_on=['Question',\n",
    "                                                                                                     'Questions and Answers']).drop(\n",
    "        'Questions and Answers', axis=1).rename(\n",
    "        columns={\"Key Name\": \"Answer Key Name\", \"BOM Fields\": \"Answer BOM Fields\"})\n",
    "    qadf = pd.concat([qdf, adf]).groupby('row').apply(\n",
    "        lambda x: x.fillna(method='ffill').fillna(method='bfill').drop_duplicates())\n",
    "    edf = filtered0Df[(filtered0Df['row'].isin(qadf['row']) == False)]\n",
    "    QnA_df = pd.concat([edf, qadf]).sort_values(['row']).drop('row', axis=1)\n",
    "    QnA_df.reset_index(drop=True, inplace=True)\n",
    "    QnA_df = QnA_df.astype(str)\n",
    "    #Cleansing\n",
    "    QnA_df[['Question Type', 'Filter Type']] = QnA_df[['Question Type']]\\\n",
    "                                                .apply(create_QuestionType_FilterType, axis=1, result_type='expand')\n",
    "    QnA_df['Question Number'] = QnA_df['Question Number'].str.replace('.0', '', regex=False)\n",
    "    QnA_df['Parent'] = QnA_df['Parent'].str.replace('.0', '', regex=False)\n",
    "    QnA_df['Answer'] = QnA_df['Answer'].str.replace('0', 'nan')\n",
    "    QnA_df['Min'] = QnA_df['Min'].str.replace('Minimum=', '')\n",
    "    QnA_df['Max'] = QnA_df['Max'].str.replace('Maximum=', '')\n",
    "    QnA_df['Classes'] = QnA_df['Classes'].str.replace('Classes = ', '')\n",
    "    QnA_df['Available Units'] = QnA_df['Available Units'].str.replace('Available Units = ', '')\n",
    "    QnA_df['Disclosure Type'] = QnA_df['Disclosure Type'].str.replace('Disclosure Type = ', '')\n",
    "    QnA_df['Questionnaire'] = QnA_df['Questionnaire'].str.replace('Questionnaire = ', '')\n",
    "    QnA_df['Version'] = 15\n",
    "    QnA_df['Entity'] = entity_mapping.loc[entity_mapping['EntityName']==entityName]['EntityNumber'].values[0]\n",
    "    QnA_df['Condition'] = conditionMapping_df.loc[conditionMapping_df['ConditionName'] == key]['ConditionNumber'].values[0]\n",
    "    QnA_df['Unique Key'] = QnA_df['Version'].astype(str) + QnA_df['Entity'].astype(str) + QnA_df['Condition'].astype(str) + \\\n",
    "                            QnA_df['Question Number']\n",
    "    QnA_df = QnA_df.replace('nan', '').replace('None', '')\n",
    "    QnA_df = QnA_df[['Unique Key', 'Version', 'Entity', 'Condition', 'Question Number', 'Parent', 'Underwriter Comments', \\\n",
    "                     'Question Key Name', 'Question BOM Fields', 'Answer Key Name', 'Answer BOM Fields', \\\n",
    "                     'Question', 'Question Type', 'Filter Type', 'Min', 'Max',\\\n",
    "                     'Answer', 'Disclosure Type', 'Questionnaire', 'Classes', 'Available Units', 'Help Text']]\n",
    "    return QnA_df\n",
    "\n",
    "\n",
    "def splitRows(df, colToSplitOn):\n",
    "    '''\n",
    "    Helper function to split rows of a dataframe based on a particular column and replicate all other columns\n",
    "    '''\n",
    "    temp = df[colToSplitOn].str.rstrip('\\n').str.split('\\n')\n",
    "    df = df.reindex(df.index.repeat(temp.apply(len)))\n",
    "    df[colToSplitOn] = np.hstack(temp)\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_ControllerAndRules_tables(data, table_beginning_rows_dict, table):\n",
    "    '''\n",
    "    Function to create dataframe for the Controller/Rules table as required after identifying rows and columns and splitting\n",
    "    '''\n",
    "    if table == 'Controller': \n",
    "        if len(table_beginning_rows_dict['Controller_table_beginning_rows']) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            df_dict = {}\n",
    "            for i in range(len(table_beginning_rows_dict['Controller_table_beginning_rows'])):\n",
    "                table_beginning_row = np.int32(table_beginning_rows_dict['Controller_table_beginning_rows'][i])\n",
    "                if i == len(table_beginning_rows_dict['Controller_table_beginning_rows']) - 1:\n",
    "                    if len(table_beginning_rows_dict['Rules_table_beginning_rows']) == 0:\n",
    "                        table_end_row = data.shape[0]\n",
    "                    else:\n",
    "                        table_end_row = np.int32(table_beginning_rows_dict['Rules_table_beginning_rows'][0]) - 1\n",
    "                else:\n",
    "                    table_end_row = np.int32(table_beginning_rows_dict['Controller_table_beginning_rows'][i+1]) - 1\n",
    "                col = 0\n",
    "                table_end_Found = False\n",
    "                while (table_end_Found == False) & (col < data.shape[1]):\n",
    "                    if pd.isna(data.iloc[table_beginning_row + 1, col]) == True:\n",
    "                        table_end_Found = True\n",
    "                    else:\n",
    "                        col += 1  \n",
    "                df = data.iloc[table_beginning_row+2:table_end_row+1, 0:col]\n",
    "                df.columns = data.iloc[table_beginning_row+1, 0:col].tolist()\n",
    "                                            \n",
    "                df.dropna(inplace=True, how='all')\n",
    "                df.fillna('', inplace=True)\n",
    "                df.reset_index(drop=True, inplace=True)\n",
    "                df.columns = [re.sub(' +',' ',col) for col in df.columns]\n",
    "                if 'Product Class' not in df.columns:\n",
    "                    df['Product Class'] = ''\n",
    "                df = splitRows(df, 'Product Class')\n",
    "                df_dict[i] = df\n",
    "            return df_dict\n",
    "\n",
    "    elif table == 'Rules':\n",
    "        if len(table_beginning_rows_dict['Rules_table_beginning_rows']) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            table_beginning_row = np.int32(table_beginning_rows_dict['Rules_table_beginning_rows'][0])\n",
    "            table_end_row = data.shape[0] + 1\n",
    "            col = 0\n",
    "            table_end_Found = False\n",
    "            while (table_end_Found == False) & (col < data.shape[1]):\n",
    "                if pd.isna(data.iloc[table_beginning_row + 1, col]) == True:\n",
    "                    table_end_Found = True\n",
    "                else:\n",
    "                    col += 1  \n",
    "\n",
    "            df = data.iloc[table_beginning_row+2:table_end_row, 0:col]\n",
    "            df.columns = data.iloc[table_beginning_row+1, 0:col].tolist()\n",
    "            df.dropna(inplace=True, how='all')\n",
    "            df.fillna('', inplace=True)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "            df.columns = [re.sub(' +',' ',col) for col in df.columns]\n",
    "            df.columns = [col.replace('SinceLast', 'Since Last') if 'SinceLast' in col else col for col in df.columns]\n",
    "            if 'Product Class' not in df.columns:\n",
    "                df['Product Class'] = ''\n",
    "            df = splitRows(df, 'Product Class')\n",
    "            return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def createFinalOutput(sheetKey, table_beginning_rows_dict, QnA_df, Controller_df_dict, Rules_df):\n",
    "    if sheetKey == 'Interview':\n",
    "        ControllerTableRows_df = pd.DataFrame()\n",
    "        for i in range(QnA_df.shape[0]):\n",
    "            key = sheetKey\n",
    "            if (QnA_df['Questionnaire'].iloc[i] != '') & (QnA_df['Disclosure Type'].iloc[i] != ''):\n",
    "                disclosureType = QnA_df['Disclosure Type'].iloc[i]\n",
    "                if QnA_df['Questionnaire'].iloc[i].find('Overrides') == -1:\n",
    "                    questionnaire = QnA_df['Questionnaire'].iloc[i].replace(' - Default', '').strip()\n",
    "                if (questionnaire is not None) & (questionnaire not in neither_Rules_nor_Controller) & \\\n",
    "                    (LinkedQuestionnaireField_mapping.loc[LinkedQuestionnaireField_mapping['Linked worksheet'] \\\n",
    "                                                                     ==questionnaire].shape[0] > 0):\n",
    "                    fieldName = LinkedQuestionnaireField_mapping.loc[LinkedQuestionnaireField_mapping['Linked worksheet'] \\\n",
    "                                                                     ==questionnaire]['Controller'].values[0]\n",
    "                    for dict_key in newData[questionnaire]['Controller_df_dict'].keys():\n",
    "                        temp = newData[questionnaire]['Controller_df_dict'][dict_key]\n",
    "                        if 'Risk Name' in temp.columns:\n",
    "                            condition = ((temp[fieldName] == disclosureType) | (temp['Risk Name'] == disclosureType))\n",
    "                        else:\n",
    "                            condition = (temp[fieldName] == disclosureType)\n",
    "                        if temp.loc[condition].shape[0] > 0:\n",
    "                            temp_Controller = temp.loc[condition]\n",
    "                            temp_Controller['Row_Number'] = QnA_df.index[i]\n",
    "                            temp_Controller['Controller Table Field'] = fieldName\n",
    "                            ControllerTableRows_df = pd.concat([ControllerTableRows_df, temp_Controller]).fillna('')\n",
    "                            break\n",
    "        ControllerTableRows_df.columns = [col if col == 'Controller Table Field' else 'C - ' + col for col in ControllerTableRows_df.columns]\n",
    "        if ControllerTableRows_df.shape[0] > 0:\n",
    "            final_df = QnA_df.merge(ControllerTableRows_df, left_index=True, right_on='C - Row_Number', how='left')\n",
    "            final_df.drop(['C - Row_Number'] ,axis=1, inplace=True)\n",
    "            final_df.fillna('', inplace=True)\n",
    "            final_df.fillna('', inplace=True)\n",
    "        else:\n",
    "            final_df = QnA_df\n",
    "        return final_df\n",
    "    \n",
    "    elif sheetKey in neither_Rules_nor_Controller or sheetKey in Controller_but_no_Rules:\n",
    "        conditionName = sheetKey.split('-')[1].strip()\n",
    "        ControllerTableRows_df = pd.DataFrame()\n",
    "        for i in range(QnA_df.shape[0]):\n",
    "            key = sheetKey\n",
    "            if (QnA_df['Questionnaire'].iloc[i] != '') & (QnA_df['Disclosure Type'].iloc[i] != ''):\n",
    "                disclosureType = QnA_df['Disclosure Type'].iloc[i]\n",
    "                if QnA_df['Questionnaire'].iloc[i].find('Overrides') == -1:\n",
    "                    questionnaire = QnA_df['Questionnaire'].iloc[i].replace(' - Default', '').strip()\n",
    "                elif QnA_df['Questionnaire'].iloc[i].find('Overrides') != -1:\n",
    "                    if overrideMapping_df.loc[(overrideMapping_df['Main DT'] == disclosureType) & \\\n",
    "                                                           (overrideMapping_df['Associated DT'] == conditionName)].shape[0] > 0:\n",
    "                        questionnaire = overrideMapping_df.loc[(overrideMapping_df['Main DT'] == disclosureType) & \\\n",
    "                                                           (overrideMapping_df['Associated DT'] == conditionName)] \\\n",
    "                                                            ['Override Questionnaire'].values[0]\n",
    "                    else:\n",
    "                        questionnaire = None\n",
    "\n",
    "                if (questionnaire is not None) & (questionnaire not in neither_Rules_nor_Controller) & \\\n",
    "                    (LinkedQuestionnaireField_mapping.loc[LinkedQuestionnaireField_mapping['Linked worksheet'] \\\n",
    "                                                                     ==questionnaire].shape[0] > 0):\n",
    "                    fieldName = LinkedQuestionnaireField_mapping.loc[LinkedQuestionnaireField_mapping['Linked worksheet'] \\\n",
    "                                                                     ==questionnaire]['Controller'].values[0]\n",
    "                    for dict_key in newData[questionnaire]['Controller_df_dict'].keys():\n",
    "                        temp = newData[questionnaire]['Controller_df_dict'][dict_key]\n",
    "                        if 'Risk Name' in temp.columns:\n",
    "                            condition = ((temp[fieldName] == disclosureType) | (temp['Risk Name'] == disclosureType))\n",
    "                        else:\n",
    "                            condition = (temp[fieldName] == disclosureType)\n",
    "                        if temp.loc[condition].shape[0] > 0:\n",
    "                            temp_Controller = temp.loc[condition]\n",
    "                            temp_Controller['Row_Number'] = QnA_df.index[i]\n",
    "                            temp_Controller['Controller Table Field'] = fieldName\n",
    "                            ControllerTableRows_df = pd.concat([ControllerTableRows_df, temp_Controller]).fillna('')\n",
    "                            break\n",
    "            \n",
    "            if (QnA_df['Question Type'].iloc[i] != 'Text Area Question') & \\\n",
    "                (QnA_df['Answer'].iloc[i] not in ['No', 'None of These']) & \\\n",
    "                (key in ['Aviation Experience - Flying', 'Aviation Experience - Sky Sports', 'Climbing Experience â€“ Hiking',\\\n",
    "                         'Lifestyle Activity - Motor Sport', 'Underwater Diving - Scuba Diving']):\n",
    "                for dict_key in newData[key]['Controller_df_dict'].keys():\n",
    "                    temp_Controller = newData[key]['Controller_df_dict'][dict_key]\n",
    "                    temp_Controller['Row_Number'] = QnA_df.index[i]\n",
    "                    temp_Controller['Controller Table Field'] = ''\n",
    "                    ControllerTableRows_df = pd.concat([ControllerTableRows_df, temp_Controller]).fillna('')\n",
    "            \n",
    "        ControllerTableRows_df.columns = [col if col == 'Controller Table Field' else 'C - ' + col for col in ControllerTableRows_df.columns]\n",
    "        if ControllerTableRows_df.shape[0] > 0:\n",
    "            final_df = QnA_df.merge(ControllerTableRows_df, left_index=True, right_on='C - Row_Number', how='left')\n",
    "            final_df.drop(['C - Row_Number'] ,axis=1, inplace=True)\n",
    "            final_df.fillna('', inplace=True)\n",
    "            final_df.fillna('', inplace=True)\n",
    "        else:\n",
    "            final_df = QnA_df\n",
    "        return final_df\n",
    "    \n",
    "    else:\n",
    "        conditionName = sheetKey.split('-')[1].strip()\n",
    "        ControllerTableRows_df = pd.DataFrame()\n",
    "        RulesTableRows_df = pd.DataFrame()\n",
    "\n",
    "        for i in range(QnA_df.shape[0]):\n",
    "            key = sheetKey\n",
    "            if QnA_df['Question BOM Fields'].iloc[i] != '':\n",
    "                bomField = QnA_df['Question BOM Fields'].iloc[i]\n",
    "                if BOMfield_mapping.loc[(BOMfield_mapping['Worksheet Key'] == key) & \\\n",
    "                                                       (BOMfield_mapping['BOM Fields'] == bomField)]['Rule Table Field'].shape[0] > 0:\n",
    "                    ruleTableField = BOMfield_mapping.loc[(BOMfield_mapping['Worksheet Key'] == key) & \\\n",
    "                                                           (BOMfield_mapping['BOM Fields'] == bomField)]['Rule Table Field'].values[0]\n",
    "                    if (ruleTableField in Rules_df.columns) & (Rules_df.shape[0] > 0):\n",
    "                        if QnA_df['Disclosure Type'].iloc[i] != '':\n",
    "                            disclosureType = QnA_df['Disclosure Type'].iloc[i]\n",
    "                            if Rules_df.loc[Rules_df[ruleTableField] == disclosureType].shape[0] > 0:\n",
    "                                temp_Rules = Rules_df.loc[Rules_df[ruleTableField] == disclosureType]\n",
    "                                temp_Rules['Row_Number'] = QnA_df.index[i]\n",
    "                                temp_Rules['Rules Table Field'] = ruleTableField\n",
    "                                RulesTableRows_df = pd.concat([RulesTableRows_df, temp_Rules]).fillna('')\n",
    "                        else:\n",
    "                            if QnA_df['Question Type'].iloc[i] in ['Radio Selection', 'Check Box']:\n",
    "                                if QnA_df['Answer Key Name'].iloc[i].find('drv_') != -1:\n",
    "                                    keyName = QnA_df['Answer Key Name'].iloc[i].split(',')\n",
    "                                    keyName = [word.strip() for word in keyName if 'drv_' in word][0]\n",
    "                                    answerStringToSearch = drvMapping_df.loc[drvMapping_df['Available Reference Values'] == keyName] \\\n",
    "                                                                            ['Available Reference Values Display Name'].iloc[0]\n",
    "                                else:\n",
    "                                    answerStringToSearch = QnA_df['Answer'].iloc[i]\n",
    "                                if Rules_df.loc[Rules_df[ruleTableField] == answerStringToSearch].shape[0] > 0:\n",
    "                                    temp_Rules = Rules_df.loc[Rules_df[ruleTableField] == answerStringToSearch]\n",
    "                                    temp_Rules['Row_Number'] = QnA_df.index[i]\n",
    "                                    temp_Rules['Rules Table Field'] = ruleTableField\n",
    "                                    RulesTableRows_df = pd.concat([RulesTableRows_df, temp_Rules]).fillna('')\n",
    "                            elif (QnA_df['Question Type'].iloc[i] in ['Date Question', \\\n",
    "                                                                       'Numeric Question', 'Unitized Question']):\n",
    "                                if Rules_df.loc[Rules_df[ruleTableField] != '-'].shape[0] > 0:\n",
    "                                    temp_Rules = Rules_df.loc[Rules_df[ruleTableField] != '-']\n",
    "                                    temp_Rules['Row_Number'] = QnA_df.index[i]\n",
    "                                    temp_Rules['Rules Table Field'] = ruleTableField\n",
    "                                    RulesTableRows_df = pd.concat([RulesTableRows_df, temp_Rules]).fillna('')\n",
    "\n",
    "            if QnA_df['Answer BOM Fields'].iloc[i] != '':\n",
    "                bomField = QnA_df['Answer BOM Fields'].iloc[i]\n",
    "                if BOMfield_mapping.loc[(BOMfield_mapping['Worksheet Key'] == key) & \\\n",
    "                                       (BOMfield_mapping['BOM Fields'] == bomField)]['Rule Table Field'].shape[0] > 0:\n",
    "                    ruleTableField = BOMfield_mapping.loc[(BOMfield_mapping['Worksheet Key'] == key) & \\\n",
    "                                                           (BOMfield_mapping['BOM Fields'] == bomField)]['Rule Table Field'].values[0]\n",
    "                    if QnA_df['Disclosure Type'].iloc[i] != '':\n",
    "                        disclosureType = QnA_df['Disclosure Type'].iloc[i]\n",
    "\n",
    "                    if (ruleTableField in Rules_df.columns) & (Rules_df.shape[0] > 0):\n",
    "                        if disclosureType != '':\n",
    "                            if Rules_df.loc[Rules_df[ruleTableField] == disclosureType].shape[0] > 0:\n",
    "                                temp_Rules = Rules_df.loc[Rules_df[ruleTableField] == disclosureType]\n",
    "                                temp_Rules['Row_Number'] = QnA_df.index[i]\n",
    "                                temp_Rules['Rules Table Field'] = ruleTableField\n",
    "                                RulesTableRows_df = pd.concat([RulesTableRows_df, temp_Rules]).fillna('')\n",
    "                        else:\n",
    "                            if QnA_df['Question Type'].iloc[i] == 'Radio Selection':\n",
    "                                if QnA_df['Answer Key Name'].iloc[i].find('drv_') != -1:\n",
    "                                    keyName = QnA_df['Answer Key Name'].iloc[i].split(',')\n",
    "                                    keyName = [word.strip() for word in keyName if 'drv_' in word][0]\n",
    "                                    answerStringToSearch = drvMapping_df.loc[drvMapping_df['Available Reference Values'] == keyName] \\\n",
    "                                                                            ['Available Reference Values Display Name'].iloc[0]\n",
    "                                else:\n",
    "                                    answerStringToSearch = QnA_df['Answer'].iloc[i]\n",
    "                                if Rules_df.loc[Rules_df[ruleTableField] == answerStringToSearch].shape[0] > 0:\n",
    "                                    temp_Rules = Rules_df.loc[Rules_df[ruleTableField] == answerStringToSearch]\n",
    "                                    temp_Rules['Row_Number'] = QnA_df.index[i]\n",
    "                                    temp_Rules['Rules Table Field'] = ruleTableField\n",
    "                                    RulesTableRows_df = pd.concat([RulesTableRows_df, temp_Rules]).fillna('')\n",
    "                            elif (QnA_df['Question Type'].iloc[i] in ['Date Question', \\\n",
    "                                                                       'Numeric Question', 'Unitized Question']):\n",
    "                                if Rules_df.loc[Rules_df[ruleTableField] != '-'].shape[0] > 0:\n",
    "                                    temp_Rules = Rules_df.loc[Rules_df[ruleTableField] != '-']\n",
    "                                    temp_Rules['Row_Number'] = QnA_df.index[i]\n",
    "                                    temp_Rules['Rules Table Field'] = ruleTableField\n",
    "                                    RulesTableRows_df = pd.concat([RulesTableRows_df, temp_Rules]).fillna('')\n",
    "\n",
    "            if (QnA_df['Questionnaire'].iloc[i] != '') & (QnA_df['Disclosure Type'].iloc[i] != ''):\n",
    "                disclosureType = QnA_df['Disclosure Type'].iloc[i]\n",
    "                if QnA_df['Questionnaire'].iloc[i].find('Overrides') == -1:\n",
    "                    questionnaire = QnA_df['Questionnaire'].iloc[i].replace(' - Default', '').strip()\n",
    "                elif QnA_df['Questionnaire'].iloc[i].find('Overrides') != -1:\n",
    "                    if overrideMapping_df.loc[(overrideMapping_df['Main DT'] == disclosureType) & \\\n",
    "                                                           (overrideMapping_df['Associated DT'] == conditionName)].shape[0] > 0:\n",
    "                        questionnaire = overrideMapping_df.loc[(overrideMapping_df['Main DT'] == disclosureType) & \\\n",
    "                                                           (overrideMapping_df['Associated DT'] == conditionName)] \\\n",
    "                                                            ['Override Questionnaire'].values[0]\n",
    "                    else:\n",
    "                        questionnaire = None\n",
    "\n",
    "                if (questionnaire is not None) & (questionnaire not in neither_Rules_nor_Controller) & \\\n",
    "                    (LinkedQuestionnaireField_mapping.loc[LinkedQuestionnaireField_mapping['Linked worksheet'] \\\n",
    "                                                                     ==questionnaire].shape[0] > 0):\n",
    "                    fieldName = LinkedQuestionnaireField_mapping.loc[LinkedQuestionnaireField_mapping['Linked worksheet'] \\\n",
    "                                                                 ==questionnaire]['Controller'].values[0]\n",
    "                    for dict_key in newData[questionnaire]['Controller_df_dict'].keys():\n",
    "                        temp = newData[questionnaire]['Controller_df_dict'][dict_key]\n",
    "                        if 'Risk Name' in temp.columns:\n",
    "                            condition = ((temp[fieldName] == disclosureType) | (temp['Risk Name'] == disclosureType))\n",
    "                        else:\n",
    "                            condition = (temp[fieldName] == disclosureType)\n",
    "                        if temp.loc[condition].shape[0] > 0:\n",
    "                            temp_Controller = temp.loc[condition]\n",
    "                            temp_Controller['Row_Number'] = QnA_df.index[i]\n",
    "                            temp_Controller['Controller Table Field'] = fieldName\n",
    "                            ControllerTableRows_df = pd.concat([ControllerTableRows_df, temp_Controller]).fillna('')\n",
    "                            break\n",
    "            \n",
    "            #To handle anxiety specific case\n",
    "            if ((QnA_df['Question Type'].iloc[i] == 'Check Box') & (QnA_df['Answer BOM Fields'].iloc[i] == '') & \\\n",
    "                  (QnA_df.loc[(QnA_df['Question Number'] == QnA_df['Question Number'].iloc[i]) & (QnA_df['Answer BOM Fields'] != '')].shape[0] > 0)):\n",
    "                bomField = QnA_df.loc[(QnA_df['Question Number'] == QnA_df['Question Number'].iloc[i]) & \\\n",
    "                                      (QnA_df['Answer BOM Fields'] != '')]['Answer BOM Fields'].iloc[0]\n",
    "                if bomField == 'MedicalCondition.type':\n",
    "                    controllerTableField = 'Medical Type'\n",
    "                    string = QnA_df['Answer'].iloc[i]\n",
    "                    listToMatch = []\n",
    "                    if len(re.findall(\".*?\\((.*?)\\)\", string.strip())) > 0:\n",
    "                        listToMatch = re.sub(\" ?\\([^)]+\\)\", \"\", string.strip()).split(',') + re.findall(\".*?\\((.*?)\\)\", string.strip())[0].replace('such as', '').split(',')\n",
    "                    else:\n",
    "                        listToMatch = re.sub(\" ?\\([^)]+\\)\", \"\", string.strip()).split(',')\n",
    "                    listToMatch = [l.strip().lower() for l in listToMatch]\n",
    "                    listToMatch = [l.replace('generalised', 'generalized') for l in listToMatch]\n",
    "                    if Controller_df_dict[0].loc[Controller_df_dict[0]['Medical Type'].str.lower().apply(lambda x: re.sub(' +',' ',x)).isin(listToMatch)].shape[0] > 0:\n",
    "                        temp_Controller = Controller_df_dict[0].loc[Controller_df_dict[0]['Medical Type'].str.lower().isin(listToMatch)]\n",
    "                        temp_Controller['Row_Number'] = QnA_df.index[i]\n",
    "                        temp_Controller['Controller Table Field'] = controllerTableField\n",
    "                        ControllerTableRows_df = pd.concat([ControllerTableRows_df, temp_Controller]).fillna('')\n",
    "            \n",
    "            #To handle  heart murur specific case\n",
    "            if (conditionName == 'Heart Murmur') & (QnA_df['Question'].iloc[i].find('Do you have a history of any of the following?')!= -1):\n",
    "                temp_Controller = Controller_df_dict[0].loc[Controller_df_dict[0]['Medical Type'] == conditionName]\n",
    "                temp_Controller['Row_Number'] = QnA_df.index[i]\n",
    "                temp_Controller['Controller Table Field'] = ''\n",
    "                ControllerTableRows_df = pd.concat([ControllerTableRows_df, temp_Controller]).fillna('')\n",
    "\n",
    "        RulesTableRows_df.columns = [col if col == 'Rules Table Field' else 'R - ' + col for col in RulesTableRows_df.columns]\n",
    "        ControllerTableRows_df.columns = [col if col == 'Controller Table Field' else 'C - ' + col for col in ControllerTableRows_df.columns]\n",
    "        if (ControllerTableRows_df.shape[0] > 0) & (RulesTableRows_df.shape[0] > 0):\n",
    "            RulesControllerOutput_df = RulesTableRows_df.merge(ControllerTableRows_df, left_on=['R - Row_Number', 'R - Product Class'], \\\n",
    "                                    right_on=['C - Row_Number', 'C - Product Class'], how='outer')\n",
    "            RulesControllerOutput_df['Row_Number'] = np.where(~RulesControllerOutput_df['R - Row_Number'].isnull(), \\\n",
    "                                                             RulesControllerOutput_df['R - Row_Number'], \\\n",
    "                                                             RulesControllerOutput_df['C - Row_Number'])\n",
    "            RulesControllerOutput_df.drop(['R - Row_Number', 'C - Row_Number'], axis=1, inplace=True)\n",
    "\n",
    "            final_df = QnA_df.merge(RulesControllerOutput_df, left_index=True, right_on='Row_Number', how='left')\n",
    "            final_df.drop(['Row_Number'] ,axis=1, inplace=True)\n",
    "            final_df.fillna('', inplace=True)\n",
    "        elif (ControllerTableRows_df.shape[0] > 0) & (RulesTableRows_df.shape[0] == 0):\n",
    "            final_df = QnA_df.merge(ControllerTableRows_df, left_index=True, right_on='C - Row_Number', how='left')\n",
    "            final_df.drop(['C - Row_Number'] ,axis=1, inplace=True)\n",
    "            final_df.fillna('', inplace=True)\n",
    "        elif (ControllerTableRows_df.shape[0] == 0) & (RulesTableRows_df.shape[0] > 0):\n",
    "            final_df = QnA_df.merge(RulesTableRows_df, left_index=True, right_on='R - Row_Number', how='left')\n",
    "            final_df.drop(['R - Row_Number'] ,axis=1, inplace=True)\n",
    "            final_df.fillna('', inplace=True)\n",
    "        else:\n",
    "            final_df = QnA_df\n",
    "            final_df.fillna('', inplace=True)\n",
    "        return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditionMapping_df = pd.DataFrame(parsedResultData['Table of Contents'].iloc[8:,3])\n",
    "conditionMapping_df.columns = ['ConditionName']\n",
    "conditionMapping_df = conditionMapping_df.loc[~conditionMapping_df['ConditionName'].isin(['Interview', 'Available Reference Values', 'Overrides'])]\n",
    "conditionMapping_df.reset_index(drop=True, inplace=True)\n",
    "conditionMapping_df['ConditionNumber'] = conditionMapping_df.index + 1\n",
    "conditionMapping_df.loc[conditionMapping_df.shape[0]] = ['Interview', 9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "drvMapping_df = parsedResultData['Available Reference Values'].iloc[:,:3]\n",
    "drvMapping_df.columns = drvMapping_df.iloc[0,:]\n",
    "drvMapping_df = drvMapping_df.iloc[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "overrideMapping_df = parsedResultData['Overrides'].iloc[:,:4]\n",
    "overrideMapping_df.columns = overrideMapping_df.iloc[0,:]\n",
    "overrideMapping_df = overrideMapping_df.iloc[1:,:]\n",
    "overrideMapping_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dtRows = overrideMapping_df.loc[~overrideMapping_df['Main DT'].isnull()].index.tolist()\n",
    "for i in range(overrideMapping_df.shape[0]):\n",
    "    if i in dtRows:\n",
    "        dtToReplicate = overrideMapping_df['Main DT'].iloc[i]\n",
    "    else:\n",
    "        overrideMapping_df['Main DT'].iloc[i] = dtToReplicate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData = {}\n",
    "for key in [key for key in parsedResultData.keys() if key not in ['Table of Contents', 'Available Reference Values', 'Overrides']]:\n",
    "    temp_dict = {}\n",
    "    temp_dict['table_beginning_rows_dict'] = identify_table_beginnings(parsedResultData[key])\n",
    "    temp_dict['QnA_df'] = create_QnA_table(key, parsedResultData[key], temp_dict['table_beginning_rows_dict'])\n",
    "    temp_dict['Controller_df_dict'] = create_ControllerAndRules_tables(parsedResultData[key], temp_dict['table_beginning_rows_dict'], 'Controller')\n",
    "    temp_dict['Rules_df'] = create_ControllerAndRules_tables(parsedResultData[key], temp_dict['table_beginning_rows_dict'], 'Rules')\n",
    "    newData[key] = temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Sheets with both Controller and Rules:  76\n",
      "# Sheets with Controller but no Rules:  31\n",
      "# Sheets with no Controller but Rules:  0\n",
      "# Sheets with neither Controller nor Rules:  15\n"
     ]
    }
   ],
   "source": [
    "Controller_but_no_Rules = []\n",
    "Rules_But_no_Controller = []\n",
    "neither_Rules_nor_Controller = []\n",
    "both_Rules_and_Controller = []\n",
    "for key in [key for key in parsedResultData.keys() if key not in ['Table of Contents', 'Available Reference Values', 'Overrides']]:\n",
    "    if (newData[key]['Rules_df'] is None) & (newData[key]['Controller_df_dict'] is None):\n",
    "        neither_Rules_nor_Controller.append(key)\n",
    "    elif (newData[key]['Rules_df'] is None) & (newData[key]['Controller_df_dict'] is not None):\n",
    "        Controller_but_no_Rules.append(key)\n",
    "    elif (newData[key]['Rules_df'] is not None) & (newData[key]['Controller_df_dict'] is None):\n",
    "        Rules_But_no_Controller.append(key)\n",
    "    elif (newData[key]['Rules_df'] is not None) & (newData[key]['Controller_df_dict'] is not None):\n",
    "        both_Rules_and_Controller.append(key)\n",
    "\n",
    "print('# Sheets with both Controller and Rules: ', len(both_Rules_and_Controller))\n",
    "print('# Sheets with Controller but no Rules: ', len(Controller_but_no_Rules))\n",
    "print('# Sheets with no Controller but Rules: ', len(Rules_But_no_Controller))\n",
    "print('# Sheets with neither Controller nor Rules: ', len(neither_Rules_nor_Controller))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "finalData = {}\n",
    "for key in [key for key in newData.keys() if key not in ['Table of Contents', 'Available Reference Values', 'Overrides']]:\n",
    "    finalData[worksheetMapping[key]] = createFinalOutput(sheetKey = key,\n",
    "                        table_beginning_rows_dict = newData[key]['table_beginning_rows_dict'],\n",
    "                        QnA_df = newData[key]['QnA_df'],\n",
    "                        Controller_df_dict = newData[key]['Controller_df_dict'],\n",
    "                        Rules_df = newData[key]['Rules_df'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_xls(dict_df, path):\n",
    "    \"\"\"\n",
    "    Save a dictionary of dataframes to an excel file, with each dataframe as a seperate worksheet\n",
    "    \"\"\"\n",
    "    writer = ExcelWriter(path, engine='xlsxwriter', options = {\"strings_to_formulas\" : False })\n",
    "    for key in dict_df:\n",
    "        dict_df[key].to_excel(writer, key, index=False)\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_xls(dict_df = finalData, path = './Data/{}/PythonOutputFile.xlsx'.format(entityName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
